#sample data pipline
A data pipeline is a method in which raw data is ingested from various data sources, transformed and then ported to a data store, such as a data lake or data warehouse, for analysis. Before data flows into a data repository, it usually undergoes some data processing.
<hr>
in this repository we want test below tools:
<ul>
<li>Postgres</li>
<li>Grafana</li>
<li>Airflow</li>
</ul>